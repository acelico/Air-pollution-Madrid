{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7655e2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013ced15",
   "metadata": {},
   "outputs": [],
   "source": [
    "airqual_may=pd.read_csv(\"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\may_mo24.csv\", sep=\";\")\n",
    "airqual_abr=pd.read_csv(\"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\abr_mo24.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6524077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numbers before the first underscore\n",
    "def extract_numbers(value):\n",
    "    return value.split('_')[0]\n",
    "\n",
    "# List of files to process with full paths\n",
    "files = [\n",
    "    r'D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\may_mo24.csv',\n",
    "    r'D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\abr_mo24.csv'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file, sep=\";\")\n",
    "    \n",
    "    # Check if the column 'PUNTO_MUESTREO' exists in the DataFrame\n",
    "    if 'PUNTO_MUESTREO' in df.columns:\n",
    "        # Create the new column and fill it with the extracted values\n",
    "        df['ID_EST'] = df['PUNTO_MUESTREO'].apply(extract_numbers)\n",
    "        \n",
    "        # Reorder columns to make the new column the first one\n",
    "        columns_order = ['ID_EST'] + [col for col in df.columns if col != 'ID_EST']\n",
    "        df = df[columns_order]\n",
    "        #drop unnecessary cols\n",
    "        df.drop(df.columns[[1, 2, 3]], axis=1, inplace=True)\n",
    "        # Find columns that start with 'V'\n",
    "        columns_with_v = [col for col in df.columns if col.startswith('V')]\n",
    "\n",
    "        # Keep rows where any of these columns have the value 'V'\n",
    "        # Variables not assigned a V correspond to not valid measurements\n",
    "        for col in columns_with_v:\n",
    "            df = df[df[col] == 'V']\n",
    "\n",
    "        # Drop all validation columns \n",
    "        df = df.loc[:, ~df.columns.str.startswith('V')]\n",
    "        # Reshape the DataFrame to have hourly data in rows\n",
    "        df_melted = df.melt(id_vars=['ID_EST', 'MAGNITUD', 'PUNTO_MUESTREO', 'ANO', 'MES', 'DIA'],\n",
    "                            var_name='HOUR', value_name='VALUE')\n",
    "        \n",
    "        # Extract the hour from the 'HOUR' column\n",
    "        df_melted['HOUR'] = df_melted['HOUR'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "        \n",
    "        # Sort the DataFrame by ID_EST, MAGNITUD, and timestamp\n",
    "        df_melted = df_melted.sort_values(by=['ID_EST', 'MAGNITUD', 'ANO', 'MES', 'DIA', 'HOUR'])\n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        output_file = file.replace('.csv', '_modified.csv')\n",
    "        df_melted.to_csv(output_file, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8698f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the modified files \n",
    "may = pd.read_csv('D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\may_mo24_modified.csv',sep=\",\")\n",
    "apr = pd.read_csv('D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\\\\abr_mo24_modified.csv',sep=\",\")\n",
    "air_data = pd.concat([apr, may], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5701d9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the resulting dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_EST</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>LONGITUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28079004</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28079004</td>\n",
       "      <td>40.423882</td>\n",
       "      <td>-3.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28079004</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28079004</td>\n",
       "      <td>40.423882</td>\n",
       "      <td>-3.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28079004</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28079004</td>\n",
       "      <td>40.423882</td>\n",
       "      <td>-3.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28079004</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28079004</td>\n",
       "      <td>40.423882</td>\n",
       "      <td>-3.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28079004</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28079004</td>\n",
       "      <td>40.423882</td>\n",
       "      <td>-3.712257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161395</th>\n",
       "      <td>28079060</td>\n",
       "      <td>14</td>\n",
       "      <td>28079060_14_6</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>105.0</td>\n",
       "      <td>28079060</td>\n",
       "      <td>40.500548</td>\n",
       "      <td>-3.689731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161396</th>\n",
       "      <td>28079060</td>\n",
       "      <td>14</td>\n",
       "      <td>28079060_14_6</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28079060</td>\n",
       "      <td>40.500548</td>\n",
       "      <td>-3.689731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161397</th>\n",
       "      <td>28079060</td>\n",
       "      <td>14</td>\n",
       "      <td>28079060_14_6</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28079060</td>\n",
       "      <td>40.500548</td>\n",
       "      <td>-3.689731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161398</th>\n",
       "      <td>28079060</td>\n",
       "      <td>14</td>\n",
       "      <td>28079060_14_6</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>90.0</td>\n",
       "      <td>28079060</td>\n",
       "      <td>40.500548</td>\n",
       "      <td>-3.689731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161399</th>\n",
       "      <td>28079060</td>\n",
       "      <td>14</td>\n",
       "      <td>28079060_14_6</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>89.0</td>\n",
       "      <td>28079060</td>\n",
       "      <td>40.500548</td>\n",
       "      <td>-3.689731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID_EST  MAGNITUD PUNTO_MUESTREO   ANO  MES  DIA  HOUR  VALUE  \\\n",
       "0       28079004         1  28079004_1_38  2024    4    1     1    1.0   \n",
       "1       28079004         1  28079004_1_38  2024    4    1     2    1.0   \n",
       "2       28079004         1  28079004_1_38  2024    4    1     3    1.0   \n",
       "3       28079004         1  28079004_1_38  2024    4    1     4    1.0   \n",
       "4       28079004         1  28079004_1_38  2024    4    1     5    1.0   \n",
       "...          ...       ...            ...   ...  ...  ...   ...    ...   \n",
       "161395  28079060        14  28079060_14_6  2024    5   31    20  105.0   \n",
       "161396  28079060        14  28079060_14_6  2024    5   31    21  100.0   \n",
       "161397  28079060        14  28079060_14_6  2024    5   31    22   95.0   \n",
       "161398  28079060        14  28079060_14_6  2024    5   31    23   90.0   \n",
       "161399  28079060        14  28079060_14_6  2024    5   31    24   89.0   \n",
       "\n",
       "              ID    LATITUD  LONGITUD  \n",
       "0       28079004  40.423882 -3.712257  \n",
       "1       28079004  40.423882 -3.712257  \n",
       "2       28079004  40.423882 -3.712257  \n",
       "3       28079004  40.423882 -3.712257  \n",
       "4       28079004  40.423882 -3.712257  \n",
       "...          ...        ...       ...  \n",
       "161395  28079060  40.500548 -3.689731  \n",
       "161396  28079060  40.500548 -3.689731  \n",
       "161397  28079060  40.500548 -3.689731  \n",
       "161398  28079060  40.500548 -3.689731  \n",
       "161399  28079060  40.500548 -3.689731  \n",
       "\n",
       "[161400 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we merge the air_data with the coordinates of each station\n",
    "# Load the CSV file\n",
    "file_path = \"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\locations\\\\air_locations_modified.csv\"\n",
    "locations_df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "\n",
    "# Convert the ID_EST column to int to match the ID column in locations_df\n",
    "air_data['ID_EST'] = air_data['ID_EST'].astype(int)\n",
    "\n",
    "# Ensure the ID column in locations_df is also of type int (it usually should be)\n",
    "locations_df['ID'] = locations_df['ID'].astype(int)\n",
    "\n",
    "# Merge the DataFrames on the corrected ID columns\n",
    "merged_df = pd.merge(air_data, locations_df, left_on='ID_EST', right_on='ID', how='left')\n",
    "\n",
    "# Specify the directory and filename to save the combined DataFrame\n",
    "output_directory = r\"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\air data\\\\Calidad aire 2024\\\\pollution\"\n",
    "output_filename = 'air_geolocated.csv'\n",
    "output_file = os.path.join(output_directory, output_filename)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"This is the resulting dataset\")\n",
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
