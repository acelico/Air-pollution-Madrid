{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numbers before the first underscore\n",
    "def extract_numbers(value):\n",
    "    return value.split('_')[0]\n",
    "\n",
    "# List of files to process with full paths\n",
    "files = [\n",
    "    r'D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\meteo data\\\\may_meteo24.csv',\n",
    "    r'D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\meteo data\\\\abr_meteo24.csv'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file, sep=\";\")\n",
    "    \n",
    "    # Check if the column 'PUNTO_MUESTREO' exists in the DataFrame\n",
    "    if 'PUNTO_MUESTREO' in df.columns:\n",
    "        # Create the new column and fill it with the extracted values\n",
    "        df['ID_EST'] = df['PUNTO_MUESTREO'].apply(extract_numbers)\n",
    "        \n",
    "        # Reorder columns to make the new column the first one\n",
    "        columns_order = ['ID_EST'] + [col for col in df.columns if col != 'ID_EST']\n",
    "        df = df[columns_order]\n",
    "        #drop unnecessary cols\n",
    "        df.drop(df.columns[[1, 2, 3]], axis=1, inplace=True)\n",
    "        # Drop all validation columns \n",
    "        df = df.loc[:, ~df.columns.str.startswith('V')]\n",
    "        # Reshape the DataFrame to have hourly data in rows\n",
    "        df_melted = df.melt(id_vars=['ID_EST', 'MAGNITUD', 'PUNTO_MUESTREO', 'ANO', 'MES', 'DIA'],\n",
    "                            var_name='HOUR', value_name='VALUE')\n",
    "        \n",
    "        # Extract the hour from the 'HOUR' column\n",
    "        df_melted['HOUR'] = df_melted['HOUR'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "        \n",
    "        # Sort the DataFrame by ID_EST, MAGNITUD, and timestamp\n",
    "        df_melted = df_melted.sort_values(by=['ID_EST', 'MAGNITUD', 'ANO', 'MES', 'DIA', 'HOUR'])\n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        output_file = file.replace('.csv', '_modified.csv')\n",
    "        df_melted.to_csv(output_file, index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the modified files \n",
    "may = pd.read_csv('D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\meteo data\\\\may_meteo24_modified.csv',sep=\",\")\n",
    "apr = pd.read_csv('D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\meteo data\\\\abr_meteo24_modified.csv',sep=\",\")\n",
    "meteo_data = pd.concat([apr, may], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the resulting dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_EST</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>LONGITUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28079004</td>\n",
       "      <td>83</td>\n",
       "      <td>28079004_83_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>28079004</td>\n",
       "      <td>404.238.823</td>\n",
       "      <td>-37.122.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28079004</td>\n",
       "      <td>83</td>\n",
       "      <td>28079004_83_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>28079004</td>\n",
       "      <td>404.238.823</td>\n",
       "      <td>-37.122.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28079004</td>\n",
       "      <td>83</td>\n",
       "      <td>28079004_83_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>28079004</td>\n",
       "      <td>404.238.823</td>\n",
       "      <td>-37.122.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28079004</td>\n",
       "      <td>83</td>\n",
       "      <td>28079004_83_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>28079004</td>\n",
       "      <td>404.238.823</td>\n",
       "      <td>-37.122.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28079004</td>\n",
       "      <td>83</td>\n",
       "      <td>28079004_83_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>28079004</td>\n",
       "      <td>404.238.823</td>\n",
       "      <td>-37.122.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132883</th>\n",
       "      <td>28079115</td>\n",
       "      <td>86</td>\n",
       "      <td>28079115_86_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28079115</td>\n",
       "      <td>403.925.444</td>\n",
       "      <td>-3.697.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132884</th>\n",
       "      <td>28079115</td>\n",
       "      <td>86</td>\n",
       "      <td>28079115_86_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28079115</td>\n",
       "      <td>403.925.444</td>\n",
       "      <td>-3.697.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132885</th>\n",
       "      <td>28079115</td>\n",
       "      <td>86</td>\n",
       "      <td>28079115_86_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28079115</td>\n",
       "      <td>403.925.444</td>\n",
       "      <td>-3.697.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132886</th>\n",
       "      <td>28079115</td>\n",
       "      <td>86</td>\n",
       "      <td>28079115_86_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28079115</td>\n",
       "      <td>403.925.444</td>\n",
       "      <td>-3.697.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132887</th>\n",
       "      <td>28079115</td>\n",
       "      <td>86</td>\n",
       "      <td>28079115_86_98</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28079115</td>\n",
       "      <td>403.925.444</td>\n",
       "      <td>-3.697.631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132888 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID_EST  MAGNITUD  PUNTO_MUESTREO   ANO  MES  DIA  HOUR  VALUE  \\\n",
       "0       28079004        83  28079004_83_98  2024    4    1     1    6.2   \n",
       "1       28079004        83  28079004_83_98  2024    4    1     2    6.1   \n",
       "2       28079004        83  28079004_83_98  2024    4    1     3    5.7   \n",
       "3       28079004        83  28079004_83_98  2024    4    1     4    5.4   \n",
       "4       28079004        83  28079004_83_98  2024    4    1     5    5.4   \n",
       "...          ...       ...             ...   ...  ...  ...   ...    ...   \n",
       "132883  28079115        86  28079115_86_98  2024    5   31    20   16.0   \n",
       "132884  28079115        86  28079115_86_98  2024    5   31    21   18.0   \n",
       "132885  28079115        86  28079115_86_98  2024    5   31    22   20.0   \n",
       "132886  28079115        86  28079115_86_98  2024    5   31    23   23.0   \n",
       "132887  28079115        86  28079115_86_98  2024    5   31    24   27.0   \n",
       "\n",
       "              ID      LATITUD     LONGITUD  \n",
       "0       28079004  404.238.823  -37.122.567  \n",
       "1       28079004  404.238.823  -37.122.567  \n",
       "2       28079004  404.238.823  -37.122.567  \n",
       "3       28079004  404.238.823  -37.122.567  \n",
       "4       28079004  404.238.823  -37.122.567  \n",
       "...          ...          ...          ...  \n",
       "132883  28079115  403.925.444   -3.697.631  \n",
       "132884  28079115  403.925.444   -3.697.631  \n",
       "132885  28079115  403.925.444   -3.697.631  \n",
       "132886  28079115  403.925.444   -3.697.631  \n",
       "132887  28079115  403.925.444   -3.697.631  \n",
       "\n",
       "[132888 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we merge the air_data with the coordinates of each station\n",
    "# Load the CSV file\n",
    "file_path = \"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\locations\\\\meteo_locations_modified.csv\"\n",
    "locations_df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "\n",
    "# Convert the ID_EST column to int to match the ID column in locations_df\n",
    "meteo_data['ID_EST'] = meteo_data['ID_EST'].astype(int)\n",
    "\n",
    "# Ensure the ID column in locations_df is also of type int (it usually should be)\n",
    "locations_df['ID'] = locations_df['ID'].astype(int)\n",
    "\n",
    "# Merge the DataFrames on the corrected ID columns\n",
    "merged_df = pd.merge(meteo_data, locations_df, left_on='ID_EST', right_on='ID', how='left')\n",
    "\n",
    "# Specify the directory and filename to save the combined DataFrame\n",
    "output_directory = r\"D:\\\\Data projects\\\\Air pollution Madrid\\\\data\\\\meteo data\"\n",
    "output_filename = 'meteo_geolocated.csv'\n",
    "output_file = os.path.join(output_directory, output_filename)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"This is the resulting dataset\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132888 entries, 0 to 132887\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   ID_EST          132888 non-null  int32  \n",
      " 1   MAGNITUD        132888 non-null  int64  \n",
      " 2   PUNTO_MUESTREO  132888 non-null  object \n",
      " 3   ANO             132888 non-null  int64  \n",
      " 4   MES             132888 non-null  int64  \n",
      " 5   DIA             132888 non-null  int64  \n",
      " 6   HOUR            132888 non-null  int64  \n",
      " 7   VALUE           132888 non-null  float64\n",
      " 8   ID              132888 non-null  int32  \n",
      " 9   LATITUD         132888 non-null  object \n",
      " 10  LONGITUD        132888 non-null  object \n",
      "dtypes: float64(1), int32(2), int64(5), object(3)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID_EST   ANO  MES  DIA  HOUR      LATITUD     LONGITUD  HUMIDITY_REL  \\\n",
      "0  28079004  2024    4    1     1  404.238.823  -37.122.567           NaN   \n",
      "1  28079004  2024    4    1     2  404.238.823  -37.122.567           NaN   \n",
      "2  28079004  2024    4    1     3  404.238.823  -37.122.567           NaN   \n",
      "3  28079004  2024    4    1     4  404.238.823  -37.122.567           NaN   \n",
      "4  28079004  2024    4    1     5  404.238.823  -37.122.567           NaN   \n",
      "\n",
      "   PRECIPITATION  PRESSURE  SOLAR_RAD  TEMPERATURE  WIND_DIR  WIND_SPEED  \n",
      "0            NaN       NaN        NaN          6.2       NaN         NaN  \n",
      "1            NaN       NaN        NaN          6.1       NaN         NaN  \n",
      "2            NaN       NaN        NaN          5.7       NaN         NaN  \n",
      "3            NaN       NaN        NaN          5.4       NaN         NaN  \n",
      "4            NaN       NaN        NaN          5.4       NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# now turn the magnitudes into variables \n",
    "# Mapping of MAGNITUD codes to parameter names\n",
    "magnitude_mapping = {\n",
    "    80: 'ULTRAVIOLETS',\n",
    "    81: 'WIND_SPEED',\n",
    "    82: 'WIND_DIR',\n",
    "    83: 'TEMPERATURE',\n",
    "    86: 'HUMIDITY_REL',\n",
    "    87: 'PRESSURE',\n",
    "    88: 'SOLAR_RAD',\n",
    "    89: 'PRECIPITATION'\n",
    "}\n",
    "\n",
    "# Replace MAGNITUD codes with their respective names\n",
    "merged_df['MAGNITUD'] = merged_df['MAGNITUD'].map(magnitude_mapping)\n",
    "\n",
    "# Pivot the table\n",
    "merged_df_pivot = merged_df.pivot_table(index=['ID_EST', 'ANO', 'MES', 'DIA', 'HOUR', 'LATITUD', 'LONGITUD'],\n",
    "                                columns='MAGNITUD',\n",
    "                                values='VALUE').reset_index()\n",
    "\n",
    "# Flatten the columns\n",
    "merged_df_pivot.columns.name = None\n",
    "\n",
    "# Display the first few rows of the pivoted DataFrame\n",
    "print(merged_df_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID_EST     MAGNITUD  PUNTO_MUESTREO   ANO  MES  DIA  HOUR  VALUE  \\\n",
      "0  28079004  TEMPERATURE  28079004_83_98  2024    4    1     1    6.2   \n",
      "1  28079004  TEMPERATURE  28079004_83_98  2024    4    1     2    6.1   \n",
      "2  28079004  TEMPERATURE  28079004_83_98  2024    4    1     3    5.7   \n",
      "3  28079004  TEMPERATURE  28079004_83_98  2024    4    1     4    5.4   \n",
      "4  28079004  TEMPERATURE  28079004_83_98  2024    4    1     5    5.4   \n",
      "\n",
      "         ID      LATITUD     LONGITUD  \n",
      "0  28079004  404.238.823  -37.122.567  \n",
      "1  28079004  404.238.823  -37.122.567  \n",
      "2  28079004  404.238.823  -37.122.567  \n",
      "3  28079004  404.238.823  -37.122.567  \n",
      "4  28079004  404.238.823  -37.122.567  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HORA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Pivot the table\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m meteo_pivot \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mpivot_table(index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_EST\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHORA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLATITUD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLONGITUD\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m                                 columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAGNITUD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                 values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALUE\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Flatten the columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m   9173\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9174\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   9175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot_table\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9186\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   9187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9188\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot_table\n\u001b[1;32m-> 9190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pivot_table(\n\u001b[0;32m   9191\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9192\u001b[0m         values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m   9193\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   9194\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   9195\u001b[0m         aggfunc\u001b[38;5;241m=\u001b[39maggfunc,\n\u001b[0;32m   9196\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   9197\u001b[0m         margins\u001b[38;5;241m=\u001b[39mmargins,\n\u001b[0;32m   9198\u001b[0m         dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9199\u001b[0m         margins_name\u001b[38;5;241m=\u001b[39mmargins_name,\n\u001b[0;32m   9200\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9201\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:99\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     96\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m table \u001b[38;5;241m=\u001b[39m __internal_pivot_table(\n\u001b[0;32m    100\u001b[0m     data,\n\u001b[0;32m    101\u001b[0m     values,\n\u001b[0;32m    102\u001b[0m     index,\n\u001b[0;32m    103\u001b[0m     columns,\n\u001b[0;32m    104\u001b[0m     aggfunc,\n\u001b[0;32m    105\u001b[0m     fill_value,\n\u001b[0;32m    106\u001b[0m     margins,\n\u001b[0;32m    107\u001b[0m     dropna,\n\u001b[0;32m    108\u001b[0m     margins_name,\n\u001b[0;32m    109\u001b[0m     observed,\n\u001b[0;32m    110\u001b[0m     sort,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:168\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[1;32m--> 168\u001b[0m grouped \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(keys, observed\u001b[38;5;241m=\u001b[39mobserved, sort\u001b[38;5;241m=\u001b[39msort, dropna\u001b[38;5;241m=\u001b[39mdropna)\n\u001b[0;32m    169\u001b[0m agged \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39magg(aggfunc)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agged, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agged\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8879\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1279\u001b[0m         obj,\n\u001b[0;32m   1280\u001b[0m         keys,\n\u001b[0;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1286\u001b[0m     )\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HORA'"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the meteo DataFrame before pivoting\n",
    "print(merged_df.head())\n",
    "\n",
    "# Pivot the table\n",
    "meteo_pivot = merged_df.pivot_table(index=['ID_EST', 'ANO', 'MES', 'DIA', 'HORA', 'LATITUD', 'LONGITUD'],\n",
    "                                columns='MAGNITUD',\n",
    "                                values='VALUE', aggfunc='mean').reset_index()\n",
    "\n",
    "# Flatten the columns\n",
    "merged_df.columns.name = None\n",
    "\n",
    "# Display the first few rows of the pivoted DataFrame\n",
    "print(merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
